{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1471,
     "status": "ok",
     "timestamp": 1568132489221,
     "user": {
      "displayName": "Joe M",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABSZkq__6rNfwTLQQIf5_T91D5eW17TNTG_UCmyg=s64",
      "userId": "02297134086388176173"
     },
     "user_tz": 240
    },
    "id": "jI0MyEF4oYBb",
    "outputId": "e6a8ce57-b104-410e-8757-bead0c38e1fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prayt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "import json\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import webbrowser\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import sys\n",
    "import random\n",
    "from IPython.display import JSON\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "%matplotlib inline\n",
    "\n",
    "#demoji.download_codes()\n",
    "#access_token = os.environ['ACCESS_TOKEN']\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpl6ag4moYBg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 15:22:10.877324 21408 deprecation_wrapper.py:119] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0917 15:22:34.018769 21408 deprecation_wrapper.py:119] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0917 15:22:34.917285 21408 deprecation_wrapper.py:119] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0917 15:22:49.072157 21408 deprecation_wrapper.py:119] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0917 15:22:49.144138 21408 deprecation.py:506] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0917 15:22:53.886405 21408 deprecation_wrapper.py:119] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0917 15:24:23.356214 21408 deprecation_wrapper.py:119] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0917 15:24:24.681509 21408 deprecation.py:323] From C:\\Users\\prayt\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# stemmed_words_dset = {'dataset': dataset}\n",
    "# with open('/content/drive/My Drive/stemmed_words_dset.pickle', 'wb') as f:\n",
    "#     pickle.dump(stemmed_words_dset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Predictions added for WHOLE dataset, binary 1/0 also added for data that was prelabeled r/d also added to dset\n",
    "# predictions_dataset = {'dataset': dataset}\n",
    "# with open('/content/drive/My Drive/predictions_dataset.pickle', 'wb') as f:\n",
    "#     pickle.dump(predictions_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# predictions_plus_stemmed_rnn_ready_texts = {'dataset': dataset}\n",
    "# with open('/content/drive/My Drive/predictions_plus_stemmed_rnn_ready_texts.pickle', 'wb') as f:\n",
    "#     pickle.dump(predictions_plus_stemmed_rnn_ready_texts, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('/content/drive/My Drive/keyword_dset.pickle', 'rb') as f:\n",
    "#     a_pickle = pickle.load(f)\n",
    "# other_dataset = a_pickle['keyword_dset']\n",
    "# # # congress = a_pickle['congress']\n",
    "\n",
    "# with open('/content/drive/My Drive/stemmed_words_dset.pickle', 'rb') as f:\n",
    "#     a_pickle = pickle.load(f)\n",
    "# dataset = a_pickle['dataset']\n",
    "\n",
    "# with open('/content/drive/My Drive/predictions_dataset.pickle', 'rb') as f:\n",
    "#     a_pickle = pickle.load(f)\n",
    "# other_dataset = a_pickle['dataset']\n",
    "\n",
    "with open('predictions_plus_stemmed_rnn_ready_texts.pickle', 'rb') as f:\n",
    "    a_pickle = pickle.load(f);\n",
    "dataset = a_pickle['dataset']\n",
    "\n",
    "with open('rnn_model_3.pickle', 'rb') as f:\n",
    "    lstm_pickle = pickle.load(f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_stem(text):\n",
    "    text = str(text)\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPX182ydoOBy"
   },
   "outputs": [],
   "source": [
    "def predict_text_lean(a_string):\n",
    "    # USER_INPUT_STRING - must be string, text preprocessing not necessary\n",
    "    print('user input:')\n",
    "    print(a_string, '\\n')\n",
    "    MAX_SEQUENCE_LENGTH = 50\n",
    "\n",
    "    lstm_model = lstm_pickle['model']\n",
    "    lstm_tokenizer = lstm_pickle['tokenizer']\n",
    "\n",
    "    a_test = lstm_tokenizer.texts_to_sequences([a_string])\n",
    "    a_padded_test = pad_sequences(a_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "\n",
    "    predictions = lstm_model.predict(x=a_padded_test)\n",
    "    predictions = predictions.flatten()\n",
    "\n",
    "    for i in list(range(len(predictions))):  \n",
    "        print('input content partisan certainty', predictions[i])\n",
    "        if predictions[i] > .5:  \n",
    "          predictions[i] = 1\n",
    "          print('prediction: left lean')\n",
    "        else:\n",
    "          predictions[i] = 0\n",
    "          print('prediction: right lean')\n",
    "\n",
    "    user_predict = int(predictions)\n",
    "    return user_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_fit = tfidf.fit_transform(dataset['ad_stemmed_body'])\n",
    "\n",
    "def alt_tfidf_recommendations(a_string, df, predicted_lean):\n",
    "    #tfidf = TfidfVectorizer(stop_words='english')\n",
    "    #tfidf_fit = tfidf.fit_transform(df['ad_stemmed_body'])\n",
    "    a_string = clean_and_stem(a_string)\n",
    "    string_vector = tfidf.transform([a_string]) \n",
    "\n",
    "    cosine_similarities = linear_kernel(string_vector, tfidf_fit).flatten()\n",
    "    probabilities_array = df['probability'].to_numpy()\n",
    "    try:\n",
    "        if predicted_lean == 0:\n",
    "            composite_score = cosine_similarities*(probabilities_array**25)\n",
    "        elif predicted_lean == 1:\n",
    "            composite_score = cosine_similarities*((1-probabilities_array)**25)\n",
    "        else:\n",
    "            print('predicted_lean is not registering as a zero or one integer')\n",
    "    except:\n",
    "        print('something is wrong in composite score calculation if statement')\n",
    "    composite_score[0] = -1\n",
    "    recommend_indices = composite_score.argsort()[-2:]\n",
    "    print('cosine similarity between source ad and served ads:', cosine_similarities[recommend_indices])\n",
    "    print('composite score partisan certainty and cosine similarity', composite_score[recommend_indices])\n",
    "    print('probabilities array val', probabilities_array[recommend_indices])\n",
    "    return recommend_indices\n",
    "\n",
    "\n",
    "def alt_lean_and_generate_predictions(input_index, df, match_on='ad_creative_body'):   \n",
    "    ad_lean = predict_text_lean(df.ad_creative_body[input_index])  #predict_text_lean should return a zero(r) or 1(d)\n",
    "    recommend_indices = alt_tfidf_recommendations(df.ad_creative_body[input_index], df, ad_lean)\n",
    "    recommends = df[match_on][recommend_indices] \n",
    "    \n",
    "    # [::-1] reverses order of recommend_indices so tabs open in opposite order\n",
    "    for ad_index in recommend_indices[::-1]:\n",
    "        #ad_2_url = df.ad_snapshot_url[ad_index]\n",
    "        webbrowser.open(df.ad_snapshot_url[ad_index])\n",
    "        if df.probability[ad_index] > .5:\n",
    "            print('served content', ad_index, 'predicted lean: left wing')\n",
    "        else:\n",
    "            print('served content', ad_index, 'predicted lean: right wing')\n",
    "        print(df.probability[ad_index])\n",
    "    ad_1_url = df.ad_snapshot_url[input_index]\n",
    "    webbrowser.open(ad_1_url)\n",
    "    print('\\n','served content text')\n",
    "    return recommends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend Ads\n",
    "the function below takes in a number representing an ad in the database and outputs an ad that is topically relevant but from the other end of the political spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user input:\n",
      "Last week I introduced a new bipartisan bill to repeal the Death Tax. This bill gives farmers and ranchers, as well as many others, permanent relief from estate taxes and gets rid of one of the most egregious federal taxes we still have on the books – a tax on death. \n",
      "\n",
      "The Tax Cuts and Jobs Act was able to temporary lift the ceiling on the estate tax, but that ceiling begins to fall in the near future and because of arcane US Senate rules, wasn’t made permanent. The solution is to repeal the death tax once and for all. It’s an outdated tax which hurts many Missouri farmers and families. \n",
      "\n",
      "My Estate Tax Repeal Bill gives certainty to hard-working farmers. With the passage of this bill, farmers will be able to divert funds away from estate planning and towards things like business investment and equipment and livestock purchases. \n",
      "\n",
      "Now, when we lose a loved one, we won’t be subject to a financial fiasco. We won’t have to worry if our farm will stay within our family or if they will get socked with a tax bill they can’t afford. Instead, Missouri farmers will be free from this Uncle Sam tax burden and free to do what they do best – feed and clothe the world by working the land they have for generations.\n",
      "\n",
      " \n",
      "\n",
      "input content partisan certainty 0.00045472864\n",
      "prediction: right lean\n",
      "cosine similarity between source ad and served ads: [0.43575319 0.40571312]\n",
      "composite score partisan certainty and cosine similarity [0.40369251 0.40410925]\n",
      "probabilities array val [0.99694777 0.9998416 ]\n",
      "served content 68307 predicted lean: left wing\n",
      "0.9998416\n",
      "served content 105063 predicted lean: left wing\n",
      "0.99694777\n",
      "\n",
      " served content text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105063    Sanders plans to introduce an estate tax plan with rates up to 77 percent. The \"For the 99.8% Ac...\n",
       "68307     Many Americans owe additional taxes or have smaller refunds this Tax Day, after Trump and the GO...\n",
       "Name: ad_creative_body, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any_number_between_1_and_157000 = 35235\n",
    "\n",
    "alt_lean_and_generate_predictions(any_number_between_1_and_157000, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "recommender_demo_notebook.ipynb",
   "provenance": [
    {
     "file_id": "1Oi6hyxxXOCOzqdi0UVv-aKroKXd06JrF",
     "timestamp": 1568131163869
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
